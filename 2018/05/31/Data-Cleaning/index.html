<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Python," />










<meta name="description" content="Datacamp course notes on data cleaning.">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="DataCamp - Cleaning Data in Python">
<meta property="og:url" content="http://yoursite.com/2018/05/31/Data-Cleaning/index.html">
<meta property="og:site_name" content="Joanna">
<meta property="og:description" content="Datacamp course notes on data cleaning.">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2018-06-05T22:50:45.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DataCamp - Cleaning Data in Python">
<meta name="twitter:description" content="Datacamp course notes on data cleaning.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/05/31/Data-Cleaning/"/>





  <title>DataCamp - Cleaning Data in Python | Joanna</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Joanna</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/31/Data-Cleaning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joanna">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Joanna">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">DataCamp - Cleaning Data in Python</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-31T10:44:46-07:00">
                2018-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Course-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Course Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/31/Data-Cleaning/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/05/31/Data-Cleaning/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/05/31/Data-Cleaning/" class="leancloud_visitors" data-flag-title="DataCamp - Cleaning Data in Python">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Datacamp course notes on data cleaning.<br><a id="more"></a></p>
<h1 id="Common-Data-Problems"><a href="#Common-Data-Problems" class="headerlink" title="Common Data Problems"></a>Common Data Problems</h1><ul>
<li>Inconsistent column names (capitalization)</li>
<li>Missing data</li>
<li>Outliers</li>
<li>Duplicate rows (can bias analysis and should be dropped)</li>
<li>Untidy </li>
<li>Need to process between colums</li>
<li>Column types can signal unexpected data values</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df.head()</span><br><span class="line">df.tail()</span><br><span class="line">df.columns <span class="comment">#returns column names</span></span><br><span class="line">df.shape <span class="comment">#returns dimension</span></span><br><span class="line">df.info() <span class="comment">#additional info about the df</span></span><br></pre></td></tr></table></figure>
<h1 id="Exploratory-Data-Analysis"><a href="#Exploratory-Data-Analysis" class="headerlink" title="Exploratory Data Analysis"></a>Exploratory Data Analysis</h1><h2 id="Frequency-count"><a href="#Frequency-count" class="headerlink" title="Frequency count"></a>Frequency count</h2><p><code>value_counts()</code> is a method we used here to count the number of unique values in each column in descending order<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.info() <span class="comment">#knows data type, NAs, column names</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Before this step, make sure there is no special character in the colnames. (here continent is the colname)</span></span><br><span class="line">df.continent.value_counts(dropna = <span class="keyword">False</span>) <span class="comment">#dropna = False will also counts the number of na values, if any.</span></span><br><span class="line"></span><br><span class="line">df.[<span class="string">'continent'</span>].value_counts(dropna = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Summary-Statistics"><a href="#Summary-Statistics" class="headerlink" title="Summary Statistics"></a>Summary Statistics</h2><p>On numeric data, we can use <code>df.describe()</code> to easily get the count, mean, std, and 5 important numbers</p>
<p>When the difference between <code>max</code> and <code>min</code> is rather large, it’s good to plot the data on a log scale.</p>
<h2 id="Visual-EDA"><a href="#Visual-EDA" class="headerlink" title="Visual EDA"></a>Visual EDA</h2><p>Easily display the abnormality.<br>To look at the frequencies:</p>
<ul>
<li>Boxplots for discrete data counts<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x = continent, y = population</span></span><br><span class="line">df.boxplot(column = <span class="string">'population'</span>,</span><br><span class="line">		   by = <span class="string">'continent'</span>, rot = <span class="number">90</span>)<span class="comment">#rotate the x labels for 90 degrees</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Outliers are points showed beyond or below the whiskers</p>
<ul>
<li>Histogram for continuous data counts</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">df.population.plot(<span class="string">'hist'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#customizing</span></span><br><span class="line">df[<span class="string">'Existing Zoning Sqft'</span>].plot(kind = <span class="string">'hist'</span>, </span><br><span class="line">								rot = <span class="number">70</span>, <span class="comment">#rotate the x labels for 70 degrees</span></span><br><span class="line">								logx = <span class="keyword">True</span>, <span class="comment">#log x axis</span></span><br><span class="line">								logy = <span class="keyword">True</span>) <span class="comment">#log y axis</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># slice out the outlier</span></span><br><span class="line">df[df.population &gt; <span class="number">1000000000</span>]</span><br></pre></td></tr></table></figure>
<p>Notice that not all outliers are errors, some may be valid.</p>
<p><strong>Scatter plots</strong> are used to capture the relationship between 2 numeric variables and flag potentially bad data that cannot be found by looking at 1 variable.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import necessary modules</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create and display the first scatter plot</span></span><br><span class="line">df.plot(kind = <span class="string">'scatter'</span>, </span><br><span class="line">		x = <span class="string">'initial_cost'</span>, </span><br><span class="line">		y=<span class="string">'total_est_fee'</span>, </span><br><span class="line">		rot=<span class="number">70</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create and display the second scatter plot</span></span><br><span class="line">df_subset.plot(kind = <span class="string">'scatter'</span>, </span><br><span class="line">			   x = <span class="string">'initial_cost'</span>, </span><br><span class="line">			   y=<span class="string">'total_est_fee'</span>, </span><br><span class="line">			   rot=<span class="number">70</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h1 id="Tidy-Data"><a href="#Tidy-Data" class="headerlink" title="Tidy Data"></a>Tidy Data</h1><p>Principles of tidy data:</p>
<ol>
<li>Columns represent separate variables</li>
<li>Rows represent individual observations</li>
<li>Observational units form tables</li>
</ol>
<p>There are data formats that are better for reporting and formats that are better for analysis. </p>
<h2 id="Melting-Data"><a href="#Melting-Data" class="headerlink" title="Melting Data"></a>Melting Data</h2><p>Here, we try to fix the problem that column names containing values instead of variables with <code>pd.melt()</code>. In melting, we turn columns into rows.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pd.melt(frame = df, </span><br><span class="line">		id_vars = <span class="string">'name'</span>, <span class="comment">#columns that you don't want to melt</span></span><br><span class="line">		value_vars = [<span class="string">'treetment a'</span>, <span class="string">'treatment b'</span>],<span class="comment"># if this parameter is not specified, melt will use all the columns except the `id_vars`</span></span><br><span class="line">		var_name = <span class="string">'treatment'</span>, <span class="comment">#colname for value vars</span></span><br><span class="line">		value_name = <span class="string">'result'</span>) <span class="comment">#colname for values</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Pivoting-Data"><a href="#Pivoting-Data" class="headerlink" title="Pivoting Data"></a>Pivoting Data</h2><p>On the contrast, we can use <code>pivot()</code> method to turn unique values into separate columns, especially when multiple variables are stored in the same column.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">weather_tidy = weather.pivot(index = <span class="string">'date'</span>, <span class="comment">#column that you don't want to pivot</span></span><br><span class="line">							 columns = <span class="string">'element'</span>,<span class="comment">#pivoting column</span></span><br><span class="line">							 values = <span class="string">'value'</span>)</span><br></pre></td></tr></table></figure></p>
<p>Sometimes there are duplicate entries with different value, and will lead to error when pivoting. Here, we will use pivot table method, which has a parameter that specifies how to deal with duplicate values. e.g. it can aggregate the duplicate values by taking their averages.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">weather_tidy = weather.pivot_table(index = <span class="string">'date'</span>, <span class="comment">#column that you don't want to pivot</span></span><br><span class="line">							 columns = <span class="string">'element'</span>,<span class="comment">#pivoting column</span></span><br><span class="line">							 values = <span class="string">'value'</span>,</span><br><span class="line">							 aggfunc = np.mean)<span class="comment"># the function used to aggregate duplicates</span></span><br></pre></td></tr></table></figure></p>
<p>To deal with hierarchical index in df (they allow you to group columns or rows by another variable), we can use <code>.reset_index()</code> method to reset its index.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">airquality_pivot = airquality_pivot.reset_index()</span><br></pre></td></tr></table></figure></p>
<h2 id="Parsing-Out-Data-into-Separate-Columns"><a href="#Parsing-Out-Data-into-Separate-Columns" class="headerlink" title="Parsing Out Data into Separate Columns"></a>Parsing Out Data into Separate Columns</h2><p>Parsing out multiple values in one string into separate columns:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'sex'</span>] = df.variable.str[<span class="number">0</span>] <span class="comment">#extract the first character of the variable's value to form a new column 'sex'</span></span><br></pre></td></tr></table></figure></p>
<p>If there is a delimiter between the values that we want, we can use <code>.split()</code> to split them into separate lists and then assigning them to different columns with <code>.get()</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Melt ebola: ebola_melt</span></span><br><span class="line">ebola_melt = pd.melt(ebola, id_vars = [<span class="string">'Date'</span>, <span class="string">'Day'</span>], var_name = <span class="string">'type_country'</span>, value_name=<span class="string">'counts'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the 'str_split' column</span></span><br><span class="line">ebola_melt[<span class="string">'str_split'</span>] = ebola_melt.type_country.str.split(<span class="string">'_'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the 'type' column</span></span><br><span class="line">ebola_melt[<span class="string">'type'</span>] = ebola_melt.str_split.str.get(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the 'country' column</span></span><br><span class="line">ebola_melt[<span class="string">'country'</span>] = ebola_melt.str_split.str.get(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the head of ebola_melt</span></span><br><span class="line">print(ebola_melt.head())</span><br></pre></td></tr></table></figure></p>
<h1 id="Combining-Data-for-Analysis"><a href="#Combining-Data-for-Analysis" class="headerlink" title="Combining Data for Analysis"></a>Combining Data for Analysis</h1><h2 id="Concatenating-data"><a href="#Concatenating-data" class="headerlink" title="Concatenating data"></a>Concatenating data</h2><p>Since data may not always come in 1 huge file, we sometimes need to combine them and then clean the data, or vice versa.</p>
<p>We cam easily concat dfs with <code>pd.concat()</code>. If we don’t specify <code>ignore_index = True</code>, the row index still remain the same as they were in the separate dfs, which will affect your future slicing based in index by <code>.loc</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Combining rows</span></span><br><span class="line">concatenated = pd.concat([weather_p1, weather_p2], ignore_index = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Combining columns</span></span><br><span class="line">ebola_tidy = pd.concat([ebola_melt, status_country], axis = <span class="number">1</span>) <span class="comment">#default setting is axis = 0 for row concatenation, axis = 1 specifies columns concatenation.</span></span><br></pre></td></tr></table></figure>
<h3 id="Globbing"><a href="#Globbing" class="headerlink" title="Globbing"></a>Globbing</h3><p>In order to concatenate DataFrames:</p>
<ul>
<li>They must be in a list</li>
<li>can individually load if there are a few datasets</li>
</ul>
<p>When there are too many files to concatenate, we can use the <code>glob</code> function to find files based on a pattern. Globbing is simple way for python to do pattern matching for file names. We can use various wildcards like <code>*</code> and <code>?</code> to specify a file name pattern we are looking for. </p>
<p>A wildcard is a symbol that will match any arbitrary number of characters. </p>
<ul>
<li><code>*</code> match any string. e.g. <code>*.csv</code> matches any csv files</li>
<li><code>?</code> only allows us to match one character e.g. <code>file_?.csv</code> matches <code>file_a.csv</code>, <code>file_b.csv</code> and so on.</li>
</ul>
<p>Then globbing will return a list of file names, which can be used to load files into separate DataFrames.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">csv_files = glob.glob(<span class="string">'*.csv'</span>) <span class="comment">#returns a list of file names</span></span><br><span class="line">list_data = []</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> csv_files:</span><br><span class="line">	data = pd.read_csv(filename)</span><br><span class="line">	list_data.append(data)</span><br><span class="line">	<span class="comment">#returns a list of dataframes</span></span><br><span class="line">pd.concat(list_data) <span class="comment">#concat the list of df into a single df</span></span><br></pre></td></tr></table></figure>
<h3 id="Merging-data"><a href="#Merging-data" class="headerlink" title="Merging data"></a>Merging data</h3><p>Concatenation can only happen when row or column orders are the same among dataframes. When the order is different, we need to combine the data by merging, which is very similar to joining tables in SQL. Merging will combine disparate datasets based on common columns<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.merge(left = state_populations, <span class="comment">#left df</span></span><br><span class="line">		 right = stat_codes, <span class="comment">#right df</span></span><br><span class="line">		 on = <span class="keyword">None</span>, <span class="comment">#speficy when the key column name is the same</span></span><br><span class="line">		 left_on = <span class="string">'state'</span>, <span class="comment">#left df's key column name</span></span><br><span class="line">		 right_on = <span class="string">'name'</span>) <span class="comment">#right df's key column name</span></span><br></pre></td></tr></table></figure></p>
<p>Types of merges</p>
<ol>
<li>one-one-one merge: There is no duplicate values in the key column</li>
<li>one-to-many/many-to-one merge: duplicate values in the key column</li>
<li>many-to-many: when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created.</li>
</ol>
<h1 id="Cleaning-Data-for-Analysis"><a href="#Cleaning-Data-for-Analysis" class="headerlink" title="Cleaning Data for Analysis"></a>Cleaning Data for Analysis</h1><h2 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h2><p>Dataframe’s attribute <code>df.dtypes</code> or function <code>df.info()</code> can be called to understand each column’s data type. We can use <code>.astype()</code> function to convert one data type to another.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'treatment b'</span>] = df[<span class="string">'treatment b'</span>].astype(str)<span class="comment">#to string</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'sex'</span>] = df[<span class="string">'sex'</span>].astype(<span class="string">'category'</span>)<span class="comment">#categorical variable</span></span><br><span class="line">df.sex = df.sex.astype(<span class="string">'category'</span>) <span class="comment">#same as above</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'treatment a'</span>] = pd.to_numeric(df[<span class="string">'treatment a'</span>], errors = <span class="string">'coerce'</span>) <span class="comment">#to numeric, and coerce non-convertable value into null</span></span><br></pre></td></tr></table></figure></p>
<p>Categorical dtype has several advantages:</p>
<ol>
<li>make df smaller in memory</li>
<li>make them utilizable by other Python libraries for analysis</li>
</ol>
<h2 id="Regular-Expression-to-Match-Strings"><a href="#Regular-Expression-to-Match-Strings" class="headerlink" title="Regular Expression to Match Strings"></a>Regular Expression to Match Strings</h2><p>Match pattern by regular expressions from <code>re</code> library:</p>
<ol>
<li><code>\d*</code> match any number with any digit e.g. 17</li>
<li><code>\$\d*</code> -&gt; escape the dollar sign with <code>\</code>. The dollar sign matches the end of a string if not escaped. e.g. $17</li>
<li><code>\$\d*\.\d*</code> escape the dollar sign and the dot. The dot <code>.</code> matches any one character if not escaped/ e.g. $17.00 or $17.000</li>
<li><code>\$\d*\.\d{2}</code> only two digits after the decimal point. e.g. $17.89</li>
<li><code>^\$\d*\.\d{2}$</code> specifies to start the pattern match at the beginning of the value and tell the pattern to match as the end of the value. This way, it will only do exact matching. Otherwise, string like “I have 17.89 USD” will also be matched.</li>
<li><code>\d{3}-\d{3}-\d{4}</code> -&gt; ‘123-456-7890’</li>
<li><code>[A-Z]\w*</code> -&gt; ‘Australia’. <code>[A-Z]</code> matchs any one capital letter. <code>\w*</code> match an arbitrary number of alphanumeric characters.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.complie(<span class="string">'\$\d*\.\d&#123;2&#125;'</span>)<span class="comment">#save the pattern</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the string we want to match, and this will return a match object</span></span><br><span class="line">result = pattern.match(<span class="string">'$17.89'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the match object into a boolean, which returns True</span></span><br><span class="line">bool(result) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the numeric values: matches</span></span><br><span class="line">matches = re.findall(<span class="string">'\d+'</span>, <span class="string">'the recipe calls for 10 strawberries and 1 banana'</span>) <span class="comment">#`+` is used so that the previous element is matched one or more times. This ensures that 10 is viewed as one number and not as 1 and 0.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the matches</span></span><br><span class="line">print(matches) <span class="comment">#['10', '1']</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Using-Functions"><a href="#Using-Functions" class="headerlink" title="Using Functions"></a>Using Functions</h2><p><code>apply()</code> function can be used to perform functions quickly among rows or columns<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.apply(np.mean, axis = <span class="number">0</span>) <span class="comment">#apply the mean function across columns</span></span><br><span class="line">df.apply(np.mean, axis = <span class="number">1</span>) <span class="comment">#apply the mean function across each row</span></span><br></pre></td></tr></table></figure></p>
<p>To utilize <code>apply()</code> in an actual case:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> NaN</span><br><span class="line">pattern = re.compile(<span class="string">'^\$\d*\.\d&#123;2&#125;$'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">diff_money</span><span class="params">(row, pattern)</span>:</span></span><br><span class="line">	icost = row[<span class="string">'Initial Cost'</span>]</span><br><span class="line">	tef = row[<span class="string">'Total Est. Fee'</span>]</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> bool(pattern.match(icost)) <span class="keyword">and</span> bool(pattern.match(tef)):</span><br><span class="line">		icost = icost.replace(<span class="string">'$'</span>, <span class="string">''</span>)</span><br><span class="line">		tef = tef.replace(<span class="string">'$'</span>, <span class="string">''</span>)</span><br><span class="line">		icost = float(icost)</span><br><span class="line">		tef = float(tef)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> icost - tef</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span>(NaN) <span class="comment">#or return np.nan if only np is imported</span></span><br><span class="line"></span><br><span class="line">df_subset[<span class="string">'diff'</span>] = df_subset.apply(diff_money, axis = <span class="number">1</span>, pattern = pattern) <span class="comment">#replace the need of a for loop. Here, row = df_subset.</span></span><br></pre></td></tr></table></figure></p>
<p>Using lambda function to simplify the process:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write the lambda function using replace</span></span><br><span class="line">tips[<span class="string">'total_dollar_replace'</span>] = tips.total_dollar.apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">'$'</span>, <span class="string">''</span>)) <span class="comment">#delete the dollar sign</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the lambda function using regular expressions</span></span><br><span class="line">tips[<span class="string">'total_dollar_re'</span>] = tips.total_dollar.apply(<span class="keyword">lambda</span> x: re.findall(<span class="string">'\d+\.\d+'</span>, x)[<span class="number">0</span>]) <span class="comment">#extract only the number</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the head of tips</span></span><br><span class="line">print(tips.head()) <span class="comment">#the above two approach yield the same results</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Duplicate-and-Missing-Data"><a href="#Duplicate-and-Missing-Data" class="headerlink" title="Duplicate and Missing Data"></a>Duplicate and Missing Data</h2><p>For duplicate rows, <code>.drop_duplicates()</code> method can easily delete them.</p>
<p>For missing data, <code>.info()</code> can be used to check for the existence of missing values in each column in a dataframe. There are several ways to deal with them:</p>
<ol>
<li>Leave them as they were</li>
<li>Drop them. <code>.dropna()</code> can be used to drop all the rows contains a missing value.</li>
<li>Filling the missing values. we can use <code>.fillna()</code> to fill in the value we want. We can also fill the missing values with a test statistic, such as a median (good in presence of outliers) or a mean.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fill the missing value with the string 'missing' </span></span><br><span class="line">tips_nan[<span class="string">'sex'</span>] = tips_nan[<span class="string">'sex'</span>].fillna(<span class="string">'missing'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fill the missing value in two columns with 0</span></span><br><span class="line">tips_nan[[<span class="string">'total_bill'</span>, <span class="string">'size'</span>]] = tips_nan[[<span class="string">'total_bill'</span>, <span class="string">'size'</span>]].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fill the missing value with the mean of the column</span></span><br><span class="line">tips_nan[<span class="string">'tips'</span>] = tips_nan[<span class="string">'tip'</span>].fillna(tips_nan[<span class="string">'trip'</span>].mean())</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Testing-with-Assert"><a href="#Testing-with-Assert" class="headerlink" title="Testing with Assert"></a>Testing with Assert</h2><p>We can use assert statement to programmatically check our data. For example, after we drop or fill the NaNs, we expect no missing values. We can write an assert statement to verify this. In this way, we can detect early warnings and errors before conducting analysis on our data.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> <span class="number">1</span> == <span class="number">1</span> <span class="comment">#returns nothing since it's true</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">1</span> == <span class="number">2</span> <span class="comment">#returns an AssertionError</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#`.notnull()` check whether the value is null or not, `.all()` apply the `.notnull()` to all the values in the 'Close' column</span></span><br><span class="line"><span class="keyword">assert</span> google.Close.notnull().all()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assert that there are no missing values</span></span><br><span class="line"><span class="keyword">assert</span> pd.notnull(ebola).all().all() <span class="comment">#The first `.all()` method will return a True or False for each column, while the second `.all()` method will return a single True or False.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Assert that all values are &gt;= 0</span></span><br><span class="line"><span class="keyword">assert</span> (ebola &gt;= <span class="number">0</span>).all().all()</span><br></pre></td></tr></table></figure></p>
<h1 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h1><p>Gapminder data: consists of life expectancy by country and year.<br>Let’s first sum up what we learnt so far in this course:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Useful methods</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'my_data.csv'</span>)</span><br><span class="line">df.head()</span><br><span class="line">df.info()</span><br><span class="line">df.columns</span><br><span class="line">df.describe()</span><br><span class="line">df.column.value_counts()</span><br><span class="line">df.column.plot(<span class="string">'hist'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For data quality</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cleaning_function</span><span class="params">(row_data)</span>:</span></span><br><span class="line">	<span class="comment">#data cleaning steps</span></span><br><span class="line">	<span class="keyword">return</span> ...</span><br><span class="line">df.apply(cleaning_function, axis = <span class="number">1</span>)</span><br><span class="line"><span class="keyword">assert</span> (df.column_data &gt; <span class="number">0</span>).all()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Combining data</span></span><br><span class="line">pd.merge(df1, df2, ...)</span><br><span class="line">pd.concat([df1, df2, df3, ...])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data type</span></span><br><span class="line">df.dtypes</span><br><span class="line">df[<span class="string">'column'</span>] = df[<span class="string">'column'</span>].to_numeric()</span><br><span class="line">df[<span class="string">'column'</span>] = df[<span class="string">'column'</span>].astype(str)</span><br><span class="line">df[<span class="string">'new_column'</span>] = df[<span class="string">'column_1'</span>] + df[<span class="string">'column_2'</span>]</span><br><span class="line">df[<span class="string">'new_column'</span>] = df.apply(my_function, axis = <span class="number">1</span>) <span class="comment">#row</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the file</span></span><br><span class="line">df.to_csv[<span class="string">'file_name.csv'</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="Exploratory-Analysis"><a href="#Exploratory-Analysis" class="headerlink" title="Exploratory Analysis"></a>Exploratory Analysis</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First touch</span></span><br><span class="line">g1800s.info()</span><br><span class="line">g1800s.head()</span><br><span class="line">g1800s.describe() <span class="comment">#summary statistics column wise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Import matplotlib.pyplot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the scatter plot</span></span><br><span class="line">g1800s.plot(kind = <span class="string">'scatter'</span>, x = <span class="string">'1800'</span>, y = <span class="string">'1899'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify axis labels</span></span><br><span class="line">plt.xlabel(<span class="string">'Life Expectancy by Country in 1800'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Life Expectancy by Country in 1899'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify axis limits</span></span><br><span class="line">plt.xlim(<span class="number">20</span>, <span class="number">55</span>)</span><br><span class="line">plt.ylim(<span class="number">20</span>, <span class="number">55</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>There are a surprising number of countries that fall on the diagonal line in the scatter plot. In fact, examining the DataFrame reveals that the life expectancy for 140 of the 260 countries did not change at all in the 19th century! This is possibly a result of <em>not having access to the data for all the years back then</em>. In this way, visualizing your data can help you uncover insights as well as diagnose it for errors.</p>
<h2 id="Checking-Assumptions"><a href="#Checking-Assumptions" class="headerlink" title="Checking Assumptions"></a>Checking Assumptions</h2><p>Since you are given life expectancy level data by country and year, you could ask questions about how much the average life expectancy changes over each year.</p>
<p>Before continuing, however, it’s important to make sure that the following assumptions about the data are true:</p>
<ul>
<li>‘Life expectancy’ is the first column (index 0) of the DataFrame.</li>
<li>The other columns contain either null or numeric values.</li>
<li>The numeric values are all greater than or equal to 0.</li>
<li>There is only one instance of each country.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_null_or_valid</span><span class="params">(row_data)</span>:</span></span><br><span class="line">    <span class="string">"""Function that takes a row of data,</span></span><br><span class="line"><span class="string">    drops all missing values,</span></span><br><span class="line"><span class="string">    and checks if all remaining values are greater than or equal to 0</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    no_na = row_data.dropna()[<span class="number">1</span>:<span class="number">-1</span>] <span class="comment">#drop all rows with na</span></span><br><span class="line">    numeric = pd.to_numeric(no_na) <span class="comment">#convert all values to numeric</span></span><br><span class="line">    ge0 = numeric &gt;= <span class="number">0</span> <span class="comment">#confirm all values are greater than or equal to 0</span></span><br><span class="line">    <span class="keyword">return</span> ge0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check whether the first column is 'Life expectancy'</span></span><br><span class="line"><span class="keyword">assert</span> g1800s.columns[<span class="number">0</span>] == <span class="string">'Life expectancy'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check whether the values in the row are valid</span></span><br><span class="line"><span class="keyword">assert</span> g1800s.iloc[:, <span class="number">1</span>:].apply(check_null_or_valid, axis=<span class="number">1</span>).all().all()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check that there is only one instance of each country</span></span><br><span class="line"><span class="keyword">assert</span> g1800s[<span class="string">'Life expectancy'</span>].value_counts()[<span class="number">0</span>] == <span class="number">1</span> <span class="comment">#this method counts for each unique value in the column, and rank the values based on the counts from high to low. Therefore, if the first counts = 1, then there's no duplicates in the column.</span></span><br></pre></td></tr></table></figure>
<h2 id="Assembling-the-data"><a href="#Assembling-the-data" class="headerlink" title="Assembling the data"></a>Assembling the data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Concatenate the DataFrames row-wise</span></span><br><span class="line">gapminder = pd.concat([g1800s, g1900s, g2000s])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the shape of gapminder</span></span><br><span class="line">print(gapminder.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the head of gapminder</span></span><br><span class="line">print(gapminder.head())</span><br></pre></td></tr></table></figure>
<p>All the Gapminder data, from 1800 to 2016, is now contained in one DataFrame.</p>
<h2 id="Reshaping-the-data"><a href="#Reshaping-the-data" class="headerlink" title="Reshaping the data"></a>Reshaping the data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Melt gapminder: gapminder_melt</span></span><br><span class="line">gapminder_melt = pd.melt(frame = gapminder,</span><br><span class="line">                         id_vars = <span class="string">'Life expectancy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rename the columns</span></span><br><span class="line">gapminder_melt.columns = [<span class="string">'country'</span>, <span class="string">'year'</span>, <span class="string">'life_expectancy'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the head of gapminder_melt</span></span><br><span class="line">print(gapminder_melt.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the year column to numeric</span></span><br><span class="line">gapminder.year = pd.to_numeric(gapminder.year)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test if country is of type object</span></span><br><span class="line"><span class="keyword">assert</span> gapminder.country.dtypes == np.object</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test if year is of type int64</span></span><br><span class="line"><span class="keyword">assert</span> gapminder.year.dtypes == np.int64</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test if life_expectancy is of type float64</span></span><br><span class="line"><span class="keyword">assert</span> gapminder.life_expectancy.dtypes == np.float64</span><br></pre></td></tr></table></figure>
<h2 id="Data-correctness"><a href="#Data-correctness" class="headerlink" title="Data correctness"></a>Data correctness</h2><p>Having tidied your DataFrame and checked the data types, your next task in the data cleaning process is to look at the <code>&#39;country&#39;</code> column to see if there are any special or invalid characters you may need to deal with.</p>
<p>It is reasonable to assume that country names will contain:</p>
<ul>
<li>The set of lower and upper case letters.</li>
<li>Whitespace between words.</li>
<li>Periods for any abbreviations.</li>
</ul>
<p>To confirm that this is the case, you can leverage the power of regular expressions again. For common operations like this, Python has a built-in string method - <code>str.contains()</code> - which takes a regular expression pattern, and applies it to the Series, returning <code>True</code> if there is a match, and <code>False</code> otherwise.</p>
<p>Since here you want to find the values that do not match, you have to invert the boolean, which can be done using <code>~</code>. This Boolean series can then be used to get the Series of countries that have invalid names.</p>
<p>Write a regular expression that tests your assumptions of what characters belong in <code>countries</code>:</p>
<ul>
<li>Anchor the pattern to match exactly what you want by placing a <code>^</code> in the beginning and <code>$</code> in the end.</li>
<li>Use <code>A-Za-z</code> to match the set of lower and upper case letters, <code>\.</code> to match periods, and <code>\s</code> to match whitespace between words.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the series of countries: countries</span></span><br><span class="line">countries = gapminder.country</span><br><span class="line"></span><br><span class="line"><span class="comment"># Drop all the duplicates from countries</span></span><br><span class="line">countries = countries.drop_duplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the regular expression: pattern</span></span><br><span class="line">pattern = <span class="string">'^[A-Za-z\.\s]*$'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the Boolean vector: mask</span></span><br><span class="line">mask = countries.str.contains(pattern)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Invert the mask: mask_inverse</span></span><br><span class="line">mask_inverse = ~mask </span><br><span class="line"></span><br><span class="line"><span class="comment"># Subset countries using mask_inverse: invalid_countries</span></span><br><span class="line">invalid_countries = countries.loc[mask_inverse]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print invalid_countries</span></span><br><span class="line">print(invalid_countries)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assert that country does not contain any missing values</span></span><br><span class="line"><span class="keyword">assert</span> pd.notnull(gapminder.country).all()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assert that year does not contain any missing values</span></span><br><span class="line"><span class="keyword">assert</span> pd.notnull(gapminder.year).all()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Drop the missing values</span></span><br><span class="line">gapminder = gapminder.dropna(axis = <span class="number">0</span>, how = <span class="string">'any'</span>) <span class="comment">#default setting</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the shape of gapminder</span></span><br><span class="line">print(gapminder.shape)</span><br></pre></td></tr></table></figure>
<h2 id="Data-aggregation-and-visualization"><a href="#Data-aggregation-and-visualization" class="headerlink" title="Data aggregation and visualization"></a>Data aggregation and visualization</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add first subplot</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a histogram of life_expectancy</span></span><br><span class="line">gapminder.life_expectancy.plot(kind = <span class="string">'hist'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Group gapminder: gapminder_agg</span></span><br><span class="line">gapminder_agg = gapminder.groupby(<span class="string">'year'</span>)[<span class="string">'life_expectancy'</span>].mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the head of gapminder_agg</span></span><br><span class="line">print(gapminder_agg.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the tail of gapminder_agg</span></span><br><span class="line">print(gapminder_agg.tail())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add second subplot</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a line plot of life expectancy per year</span></span><br><span class="line">gapminder_agg.plot(kind = <span class="string">'line'</span>) <span class="comment">#default setting</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add title and specify axis labels</span></span><br><span class="line">plt.title(<span class="string">'Life expectancy over the years'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Life expectancy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Year'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the plots</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save both DataFrames to csv files</span></span><br><span class="line">gapminder.to_csv(<span class="string">'gapminder.csv'</span>)</span><br><span class="line">gapminder_agg.to_csv(<span class="string">'gapminder_agg.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>Looking at the line plot, it seems like life expectancy has, as expected, increased over the years. There is a surprising dip around 1920 that may be worth further investigation!</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/31/Importing-Data1/" rel="next" title="DataCamp - Importing Data (Part 1)">
                <i class="fa fa-chevron-left"></i> DataCamp - Importing Data (Part 1)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/31/Importing-Data2/" rel="prev" title="DataCamp - Importing Data (Part 2)">
                DataCamp - Importing Data (Part 2) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Joanna</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Common-Data-Problems"><span class="nav-number">1.</span> <span class="nav-text">Common Data Problems</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Exploratory-Data-Analysis"><span class="nav-number">2.</span> <span class="nav-text">Exploratory Data Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Frequency-count"><span class="nav-number">2.1.</span> <span class="nav-text">Frequency count</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-Statistics"><span class="nav-number">2.2.</span> <span class="nav-text">Summary Statistics</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Visual-EDA"><span class="nav-number">2.3.</span> <span class="nav-text">Visual EDA</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tidy-Data"><span class="nav-number">3.</span> <span class="nav-text">Tidy Data</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Melting-Data"><span class="nav-number">3.1.</span> <span class="nav-text">Melting Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pivoting-Data"><span class="nav-number">3.2.</span> <span class="nav-text">Pivoting Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Parsing-Out-Data-into-Separate-Columns"><span class="nav-number">3.3.</span> <span class="nav-text">Parsing Out Data into Separate Columns</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Combining-Data-for-Analysis"><span class="nav-number">4.</span> <span class="nav-text">Combining Data for Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Concatenating-data"><span class="nav-number">4.1.</span> <span class="nav-text">Concatenating data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Globbing"><span class="nav-number">4.1.1.</span> <span class="nav-text">Globbing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Merging-data"><span class="nav-number">4.1.2.</span> <span class="nav-text">Merging data</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cleaning-Data-for-Analysis"><span class="nav-number">5.</span> <span class="nav-text">Cleaning Data for Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Type"><span class="nav-number">5.1.</span> <span class="nav-text">Data Type</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Regular-Expression-to-Match-Strings"><span class="nav-number">5.2.</span> <span class="nav-text">Regular Expression to Match Strings</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Using-Functions"><span class="nav-number">5.3.</span> <span class="nav-text">Using Functions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Duplicate-and-Missing-Data"><span class="nav-number">5.4.</span> <span class="nav-text">Duplicate and Missing Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Testing-with-Assert"><span class="nav-number">5.5.</span> <span class="nav-text">Testing with Assert</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Case-Study"><span class="nav-number">6.</span> <span class="nav-text">Case Study</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Exploratory-Analysis"><span class="nav-number">6.1.</span> <span class="nav-text">Exploratory Analysis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Checking-Assumptions"><span class="nav-number">6.2.</span> <span class="nav-text">Checking Assumptions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Assembling-the-data"><span class="nav-number">6.3.</span> <span class="nav-text">Assembling the data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reshaping-the-data"><span class="nav-number">6.4.</span> <span class="nav-text">Reshaping the data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-correctness"><span class="nav-number">6.5.</span> <span class="nav-text">Data correctness</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-aggregation-and-visualization"><span class="nav-number">6.6.</span> <span class="nav-text">Data aggregation and visualization</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joanna</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'sEEYEudBHdtybAJf5AQkiOl2-gzGzoHsz',
        appKey: 'cDbeqqCJt4dq4hu7C9GaCrHB',
        placeholder: 'Leave your comment here',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("sEEYEudBHdtybAJf5AQkiOl2-gzGzoHsz", "cDbeqqCJt4dq4hu7C9GaCrHB");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
